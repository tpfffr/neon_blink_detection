{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "options 60\n",
      "\n",
      "Loading clip: 1252-2023-01-26-09-38-13-5b1af4ce\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1251-2023-01-25-16-37-59-6778eeb5\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1249-2023-01-25-14-29-18-e54693e4\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1248-2023-01-25-12-59-30-e6407072\n",
      "Number of clips: 3\n",
      "\n",
      "Loading clip: 1328-2023-02-06-09-45-58-f56cc84e\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1327-2023-02-06-09-40-56-d5cf1243\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1326-2023-02-03-17-45-57-8a41f628\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1325-2023-02-03-17-46-35-11ad4b90\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1322-2023-02-03-14-25-41-7883a14f\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1318-2023-02-03-10-41-29-03c72c25\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1317-2023-02-03-09-41-14-30f69b87\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1316-2023-02-03-09-34-09-31ef7938\n",
      "Number of clips: 4\n",
      "\n",
      "Loading clip: 1311-2023-02-02-14-30-40-96be0928\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1312-2023-02-02-16-21-47-cd28e8e0\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1313-2023-02-02-16-31-53-67b1bdbe\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1329-2023-02-06-10-40-29-c4308424\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1332-2023-02-06-11-58-03-8fc75e25\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1333-2023-02-06-13-17-50-ebc1e021\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1336-2023-02-06-15-28-30-adb9dbfb\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1337-2023-02-06-15-36-31-211278ea\n",
      "Number of clips: 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/\")\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/src\")\n",
    "\n",
    "from training.evaluation import evaluate\n",
    "from training.helper import ClassifierParams, Results\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from copy import copy\n",
    "from functions.classifiers import Classifier, load_predictions, save_predictions\n",
    "from src.post_processing import classify\n",
    "of_params, pp_params, _ = get_params()\n",
    "\n",
    "from src.neon_blink_detector import get_params\n",
    "from src.features_calculator import create_grids\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from random import choices\n",
    "from training.datasets_loader import (\n",
    "    concatenate,\n",
    "    concatenate_all_samples,\n",
    ")\n",
    "from training.helper import (\n",
    "    get_augmentation_options,\n",
    "    get_export_dir,\n",
    "    get_training_dir,\n",
    ")\n",
    "from src.event_array import Samples\n",
    "from src.helper import OfParams, PPParams, AugParams\n",
    "from training.helper import get_experiment_name_new\n",
    "from training.video_loader import video_loader\n",
    "\n",
    "clip_names = np.load(\"/users/tom/git/neon_blink_detection/clip_list.npy\")\n",
    "\n",
    "of_params = OfParams(n_layers=7, layer_interval=7, average=False, img_shape=(64, 64), grid_size=4, step_size=7, window_size=11, stop_steps=3)\n",
    "\n",
    "aug_params_options = get_augmentation_options()\n",
    "aug_params = aug_params_options[0]\n",
    "\n",
    "rec = video_loader(of_params, aug_params)\n",
    "\n",
    "rec.collect(clip_names, bg_ratio=1, augment=False, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clf_scores(predictions, labels):\n",
    "\n",
    "    pred = copy(predictions)\n",
    "    pred[pred == 1] = 0\n",
    "    pred[pred == 2] = 1\n",
    "    lab = copy(labels)\n",
    "    lab[lab == 1] = 0\n",
    "    lab[lab == 2] = 1\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    scores[\"recall_off\"] = recall_score(lab, pred)\n",
    "    scores[\"precision_off\"] = precision_score(lab, pred)\n",
    "    scores[\"f1_off\"] = f1_score(lab, pred)\n",
    "\n",
    "    pred = copy(predictions)\n",
    "    pred[pred == 2] = 0\n",
    "    pred[pred == 1] = 1\n",
    "    lab = copy(labels)\n",
    "    lab[lab == 2] = 0\n",
    "    lab[lab == 1] = 1\n",
    "\n",
    "    scores[\"recall_on\"] = recall_score(lab, pred)\n",
    "    scores[\"precision_on\"] = precision_score(lab, pred)\n",
    "    scores[\"f1_on\"] = f1_score(lab, pred)\n",
    "\n",
    "    pred = copy(predictions)\n",
    "    pred[pred > 0] = 1\n",
    "    lab = copy(labels)\n",
    "    lab[lab > 0] = 1\n",
    "\n",
    "    scores[\"recall_all\"] = recall_score(lab, pred)\n",
    "    scores[\"precision_all\"] = precision_score(lab, pred)\n",
    "    scores[\"f1_all\"] = f1_score(lab, pred)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.pipeline import get_classifier_params\n",
    "\n",
    "classifier_params = get_classifier_params()\n",
    "\n",
    "training_dir = get_training_dir(classifier_params.name, False)\n",
    "export_dir = get_export_dir(classifier_params.name, False)\n",
    "\n",
    "experiment_name = get_experiment_name_new(of_params, aug_params)\n",
    "save_path = training_dir / experiment_name\n",
    "export_path = export_dir / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "features = concatenate(rec.all_features, clip_names)\n",
    "samples_gt = concatenate_all_samples(rec.all_samples, clip_names)\n",
    "labels = samples_gt.labels\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "scores_train = []\n",
    "scores_test = []\n",
    "i = 0\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    x_train, x_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    classifier = Classifier(classifier_params, export_path)\n",
    "    classifier.on_fit(x_train, y_train)\n",
    "\n",
    "    predictions = classifier.predict(x_train)\n",
    "    predictions = classify(predictions, pp_params)\n",
    "\n",
    "    scores_train.append(f1_score(y_train, predictions, average=None))\n",
    "\n",
    "    predictions = classifier.predict(x_test)\n",
    "    predictions = classify(predictions, pp_params)\n",
    "\n",
    "    scores_test.append(f1_score(y_test, predictions, average=None))\n",
    "\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Training F1 scores ----------------\n",
      "['Bg: 0.97, ', 'Bg: 0.98, ', 'Bg: 0.97, ', 'Bg: 0.97, ', 'Bg: 0.97, ']\n",
      "['On: 0.91, ', 'On: 0.91, ', 'On: 0.92, ', 'On: 0.91, ', 'On: 0.91, ']\n",
      "['Off: 0.91, ', 'Off: 0.92, ', 'Off: 0.91, ', 'Off: 0.91, ', 'Off: 0.91, ']\n",
      "---------------- Test F1 scores ----------------\n",
      "['Bg: 0.95, ', 'Bg: 0.94, ', 'Bg: 0.94, ', 'Bg: 0.95, ', 'Bg: 0.95, ']\n",
      "['On: 0.81, ', 'On: 0.84, ', 'On: 0.79, ', 'On: 0.80, ', 'On: 0.83, ']\n",
      "['Off: 0.85, ', 'Off: 0.82, ', 'Off: 0.83, ', 'Off: 0.83, ', 'Off: 0.82, ']\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- Training F1 scores ----------------\")\n",
    "print([f\"Bg: {np.array(scores_train)[x, 0]:.2f}, \" for x in range(0, 5)])\n",
    "print([f\"On: {np.array(scores_train)[x, 1]:.2f}, \" for x in range(0, 5)])\n",
    "print([f\"Off: {np.array(scores_train)[x, 2]:.2f}, \" for x in range(0, 5)])\n",
    "\n",
    "print(\"---------------- Test F1 scores ----------------\")\n",
    "print([f\"Bg: {np.array(scores_test)[x, 0]:.2f}, \" for x in range(0, 5)])\n",
    "print([f\"On: {np.array(scores_test)[x, 1]:.2f}, \" for x in range(0, 5)])\n",
    "print([f\"Off: {np.array(scores_test)[x, 2]:.2f}, \" for x in range(0, 5)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Small training set (20%) and large validation set (80%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "features = concatenate(rec.all_features, clip_names)\n",
    "samples_gt = concatenate_all_samples(rec.all_samples, clip_names)\n",
    "labels = samples_gt.labels\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "scores_train = []\n",
    "scores_test = []\n",
    "i = 0\n",
    "\n",
    "for test, train in kf.split(X):\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    x_train, x_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    classifier = Classifier(classifier_params, export_path)\n",
    "    classifier.on_fit(x_train, y_train)\n",
    "\n",
    "    predictions = classifier.predict(x_train)\n",
    "    predictions = classify(predictions, pp_params)\n",
    "\n",
    "    scores_train.append(f1_score(y_train, predictions, average=None))\n",
    "\n",
    "    predictions = classifier.predict(x_test)\n",
    "    predictions = classify(predictions, pp_params)\n",
    "\n",
    "    scores_test.append(f1_score(y_test, predictions, average=None))\n",
    "\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scores for small training (20%) and large validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Training F1 scores ----------------\n",
      "['Bg: 1.00, ', 'Bg: 0.99, ', 'Bg: 0.99, ', 'Bg: 0.99, ', 'Bg: 1.00, ']\n",
      "['On: 0.98, ', 'On: 0.98, ', 'On: 0.98, ', 'On: 0.98, ', 'On: 0.99, ']\n",
      "['Off: 0.98, ', 'Off: 0.98, ', 'Off: 0.98, ', 'Off: 0.98, ', 'Off: 0.99, ']\n",
      "---------------- Test F1 scores ----------------\n",
      "['Bg: 0.94, ', 'Bg: 0.93, ', 'Bg: 0.94, ', 'Bg: 0.92, ', 'Bg: 0.93, ']\n",
      "['On: 0.76, ', 'On: 0.73, ', 'On: 0.81, ', 'On: 0.77, ', 'On: 0.74, ']\n",
      "['Off: 0.78, ', 'Off: 0.73, ', 'Off: 0.82, ', 'Off: 0.78, ', 'Off: 0.78, ']\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- Training F1 scores ----------------\")\n",
    "print([f\"Bg: {np.array(scores_train)[x, 0]:.2f}, \" for x in range(0, 5)])\n",
    "print([f\"On: {np.array(scores_train)[x, 1]:.2f}, \" for x in range(0, 5)])\n",
    "print([f\"Off: {np.array(scores_train)[x, 2]:.2f}, \" for x in range(0, 5)])\n",
    "\n",
    "print(\"---------------- Test F1 scores ----------------\")\n",
    "print([f\"Bg: {np.array(scores_test)[x, 0]:.2f}, \" for x in range(0, 5)])\n",
    "print([f\"On: {np.array(scores_test)[x, 1]:.2f}, \" for x in range(0, 5)])\n",
    "print([f\"Off: {np.array(scores_test)[x, 2]:.2f}, \" for x in range(0, 5)])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Even smaller training (10%) and larger validation set (90%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "features = concatenate(rec.all_features, clip_names)\n",
    "samples_gt = concatenate_all_samples(rec.all_samples, clip_names)\n",
    "labels = samples_gt.labels\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "scores_train = []\n",
    "scores_test = []\n",
    "i = 0\n",
    "\n",
    "for test, train in kf.split(X):\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    x_train, x_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    classifier = Classifier(classifier_params, export_path)\n",
    "    classifier.on_fit(x_train, y_train)\n",
    "\n",
    "    predictions = classifier.predict(x_train)\n",
    "    predictions = classify(predictions, pp_params)\n",
    "\n",
    "    scores_train.append(f1_score(y_train, predictions, average=None))\n",
    "\n",
    "    predictions = classifier.predict(x_test)\n",
    "    predictions = classify(predictions, pp_params)\n",
    "\n",
    "    scores_test.append(f1_score(y_test, predictions, average=None))\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Training F1 scores ----------------\n",
      "['Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ']\n",
      "['On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ']\n",
      "['Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ']\n",
      "---------------- Test F1 scores ----------------\n",
      "['Bg: 0.93, ', 'Bg: 0.93, ', 'Bg: 0.93, ', 'Bg: 0.93, ', 'Bg: 0.93, ', 'Bg: 0.94, ', 'Bg: 0.93, ', 'Bg: 0.92, ', 'Bg: 0.93, ', 'Bg: 0.93, ']\n",
      "['On: 0.73, ', 'On: 0.71, ', 'On: 0.73, ', 'On: 0.73, ', 'On: 0.73, ', 'On: 0.79, ', 'On: 0.76, ', 'On: 0.74, ', 'On: 0.70, ', 'On: 0.74, ']\n",
      "['Off: 0.75, ', 'Off: 0.75, ', 'Off: 0.73, ', 'Off: 0.74, ', 'Off: 0.76, ', 'Off: 0.81, ', 'Off: 0.76, ', 'Off: 0.76, ', 'Off: 0.77, ', 'Off: 0.76, ']\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- Training F1 scores ----------------\")\n",
    "print([f\"Bg: {np.array(scores_train)[x, 0]:.2f}, \" for x in range(0, 10)])\n",
    "print([f\"On: {np.array(scores_train)[x, 1]:.2f}, \" for x in range(0, 10)])\n",
    "print([f\"Off: {np.array(scores_train)[x, 2]:.2f}, \" for x in range(0, 10)])\n",
    "\n",
    "print(\"---------------- Test F1 scores ----------------\")\n",
    "print([f\"Bg: {np.array(scores_test)[x, 0]:.2f}, \" for x in range(0, 10)])\n",
    "print([f\"On: {np.array(scores_test)[x, 1]:.2f}, \" for x in range(0, 10)])\n",
    "print([f\"Off: {np.array(scores_test)[x, 2]:.2f}, \" for x in range(0, 10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "on_fit took 1.8 s\n",
      "1\n",
      "on_fit took 1.8 s\n",
      "2\n",
      "on_fit took 1.7 s\n",
      "3\n",
      "on_fit took 1.2 s\n",
      "4\n",
      "on_fit took 950 ms\n",
      "5\n",
      "on_fit took 1.0 s\n",
      "6\n",
      "on_fit took 1.1 s\n",
      "7\n",
      "on_fit took 956 ms\n",
      "8\n",
      "on_fit took 1.1 s\n",
      "9\n",
      "on_fit took 1.1 s\n",
      "10\n",
      "on_fit took 978 ms\n",
      "11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y[train], y[test]\n\u001b[1;32m     23\u001b[0m classifier \u001b[39m=\u001b[39m Classifier(classifier_params, export_path)\n\u001b[0;32m---> 24\u001b[0m classifier\u001b[39m.\u001b[39;49mon_fit(x_train, y_train)\n\u001b[1;32m     26\u001b[0m predictions \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(x_train)\n\u001b[1;32m     27\u001b[0m predictions \u001b[39m=\u001b[39m classify(predictions, pp_params)\n",
      "File \u001b[0;32m/users/tom/git/neon_blink_detection/functions/utils.py:17\u001b[0m, in \u001b[0;36mtimer.<locals>.wrapper_timer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper_timer\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     16\u001b[0m     t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m---> 17\u001b[0m     output \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     18\u001b[0m     t2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m     20\u001b[0m     run_time \u001b[39m=\u001b[39m t2 \u001b[39m-\u001b[39m t1\n",
      "File \u001b[0;32m/users/tom/git/neon_blink_detection/functions/classifiers.py:26\u001b[0m, in \u001b[0;36mClassifier.on_fit\u001b[0;34m(self, features, labels)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m@timer\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_fit\u001b[39m(\u001b[39mself\u001b[39m, features: np\u001b[39m.\u001b[39mndarray, labels: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfeatures shape=\u001b[39m\u001b[39m{\u001b[39;00mfeatures\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclf\u001b[39m.\u001b[39;49mfit(features, labels)\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/xgboost/core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    505\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 506\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/xgboost/sklearn.py:1250\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1230\u001b[0m model, feval, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(xgb_model, eval_metric, params)\n\u001b[1;32m   1231\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1232\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1233\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     label_transform\u001b[39m=\u001b[39mlabel_transform,\n\u001b[1;32m   1248\u001b[0m )\n\u001b[0;32m-> 1250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1251\u001b[0m     params,\n\u001b[1;32m   1252\u001b[0m     train_dmatrix,\n\u001b[1;32m   1253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1254\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1255\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1256\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1257\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1258\u001b[0m     feval\u001b[39m=\u001b[39;49mfeval,\n\u001b[1;32m   1259\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1260\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1261\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1262\u001b[0m )\n\u001b[1;32m   1264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, evals\u001b[39m=\u001b[39m(), obj\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, feval\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, early_stopping_rounds\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, evals_result\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, xgb_model\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, callbacks\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[39m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[39m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[39m=\u001b[39m _train_internal(params, dtrain,\n\u001b[1;32m    189\u001b[0m                           num_boost_round\u001b[39m=\u001b[39;49mnum_boost_round,\n\u001b[1;32m    190\u001b[0m                           evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m    191\u001b[0m                           obj\u001b[39m=\u001b[39;49mobj, feval\u001b[39m=\u001b[39;49mfeval,\n\u001b[1;32m    192\u001b[0m                           xgb_model\u001b[39m=\u001b[39;49mxgb_model, callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    193\u001b[0m                           verbose_eval\u001b[39m=\u001b[39;49mverbose_eval,\n\u001b[1;32m    194\u001b[0m                           evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m    195\u001b[0m                           maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    196\u001b[0m                           early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds)\n\u001b[1;32m    197\u001b[0m     \u001b[39mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/xgboost/training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m callbacks\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     80\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m callbacks\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     83\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/xgboost/core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1680\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1681\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1682\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1683\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=2000)\n",
    "\n",
    "features = concatenate(rec.all_features, clip_names)\n",
    "samples_gt = concatenate_all_samples(rec.all_samples, clip_names)\n",
    "labels = samples_gt.labels\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "scores_train = []\n",
    "scores_test = []\n",
    "i = 0\n",
    "\n",
    "for test, train in kf.split(X, y):\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    x_train, x_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    classifier = Classifier(classifier_params, export_path)\n",
    "    classifier.on_fit(x_train, y_train)\n",
    "\n",
    "    predictions = classifier.predict(x_train)\n",
    "    predictions = classify(predictions, pp_params)\n",
    "\n",
    "    scores_train.append(f1_score(y_train, predictions, average=None))\n",
    "\n",
    "    predictions = classifier.predict(x_test)\n",
    "    predictions = classify(predictions, pp_params)\n",
    "\n",
    "    scores_test.append(f1_score(y_test, predictions, average=None))\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Training F1 scores ----------------\n",
      "['Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ', 'Bg: 1.00, ']\n",
      "['On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ', 'On: 1.00, ']\n",
      "['Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ', 'Off: 1.00, ']\n",
      "---------------- Test F1 scores ----------------\n",
      "['Bg: 0.86, ', 'Bg: 0.87, ', 'Bg: 0.74, ', 'Bg: 0.87, ', 'Bg: 0.85, ', 'Bg: 0.83, ', 'Bg: 0.82, ', 'Bg: 0.87, ', 'Bg: 0.82, ', 'Bg: 0.87, ']\n",
      "['On: 0.37, ', 'On: 0.33, ', 'On: 0.39, ', 'On: 0.43, ', 'On: 0.36, ', 'On: 0.12, ', 'On: 0.34, ', 'On: 0.32, ', 'On: 0.37, ', 'On: 0.37, ']\n",
      "['Off: 0.57, ', 'Off: 0.45, ', 'Off: 0.50, ', 'Off: 0.50, ', 'Off: 0.50, ', 'Off: 0.33, ', 'Off: 0.48, ', 'Off: 0.41, ', 'Off: 0.45, ', 'Off: 0.37, ']\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- Training F1 scores ----------------\")\n",
    "print([f\"Bg: {np.array(scores_train)[x, 0]:.2f}, \" for x in range(0, 10)])\n",
    "print([f\"On: {np.array(scores_train)[x, 1]:.2f}, \" for x in range(0, 10)])\n",
    "print([f\"Off: {np.array(scores_train)[x, 2]:.2f}, \" for x in range(0, 10)])\n",
    "\n",
    "print(\"---------------- Test F1 scores ----------------\")\n",
    "print([f\"Bg: {np.array(scores_test)[x, 0]:.2f}, \" for x in range(0, 10)])\n",
    "print([f\"On: {np.array(scores_test)[x, 1]:.2f}, \" for x in range(0, 10)])\n",
    "print([f\"Off: {np.array(scores_test)[x, 2]:.2f}, \" for x in range(0, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7592609023557074,\n",
       " 0.7562552681779868,\n",
       " 0.6243068186859501,\n",
       " 0.7716494388004081,\n",
       " 0.739008917084424,\n",
       " 0.6790847788474336,\n",
       " 0.7069007586176301,\n",
       " 0.7363360099374473,\n",
       " 0.6994698549310145,\n",
       " 0.7573089037753427,\n",
       " 0.6759793265604898,\n",
       " 0.5673772237256555,\n",
       " 0.7028082161394792,\n",
       " 0.6808482321103766,\n",
       " 0.6589104298833237,\n",
       " 0.6673284237611463]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_fit took 166 ms\n"
     ]
    }
   ],
   "source": [
    "classifier = Classifier(classifier_params, export_path)\n",
    "classifier.on_fit(x_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(x_test)\n",
    "predictions = classify(predictions, pp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  1,  1,  0,  0,  1,  0,  0,  0,  1,  1,  1,  1,  1,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0, -1,  1,  1,  1,  1,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0, -2, -2, -2, -2, -2, -2, -2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, -2, -2, -2, -2, -2, -2, -2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1,  0, -1, -1,  0, -2, -2, -2, -2, -2, -2, -2, -2,\n",
       "       -2, -2, -2, -2, -2, -2, -2, -2, -2, -2,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  1,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  1, -1, -1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0, -1, -1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:500]-y_test[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tom_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
