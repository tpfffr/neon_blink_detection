{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "options 1\n",
      "\n",
      "Loading clip: 1318-2023-02-03-10-41-29-03c72c25\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1317-2023-02-03-09-41-14-30f69b87\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1316-2023-02-03-09-34-09-31ef7938\n",
      "Number of clips: 4\n",
      "\n",
      "Loading clip: 1311-2023-02-02-14-30-40-96be0928\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1312-2023-02-02-16-21-47-cd28e8e0\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1313-2023-02-02-16-31-53-67b1bdbe\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1329-2023-02-06-10-40-29-c4308424\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1332-2023-02-06-11-58-03-8fc75e25\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1333-2023-02-06-13-17-50-ebc1e021\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1336-2023-02-06-15-28-30-adb9dbfb\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1337-2023-02-06-15-36-31-211278ea\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1338-2023-02-06-16-29-00-adceb23d\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1339-2023-02-06-17-24-49-5b24f5ba\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1340-2023-02-06-17-37-00-e6218648\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1341-2023-02-07-10-38-42-d828e5ac\n",
      "Number of clips: 4\n",
      "\n",
      "Loading clip: 1342-2023-02-07-10-43-55-b5709e1f\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1343-2023-02-07-11-37-02-214c1078\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1345-2023-02-07-13-19-29-f5930ed0\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1344-2023-02-07-13-19-49-d1517542\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1346-2023-02-07-14-22-59-b1384544\n",
      "Number of clips: 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/\")\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/src\")\n",
    "\n",
    "from training.evaluation import evaluate\n",
    "from training.helper import ClassifierParams, Results\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from copy import copy\n",
    "from functions.classifiers import Classifier, load_predictions, save_predictions\n",
    "from src.post_processing import classify\n",
    "from src.neon_blink_detector import get_params\n",
    "of_params, pp_params, _ = get_params()\n",
    "from src.features_calculator import create_grids\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from random import choices\n",
    "from training.datasets_loader import (\n",
    "    concatenate,\n",
    "    concatenate_all_samples,\n",
    ")\n",
    "from training.helper import (\n",
    "    get_augmentation_options,\n",
    "    get_export_dir,\n",
    "    get_training_dir,\n",
    ")\n",
    "from src.event_array import Samples\n",
    "from src.helper import OfParams, PPParams, AugParams\n",
    "from training.helper import get_experiment_name_new\n",
    "from training.video_loader import video_loader\n",
    "\n",
    "clip_names = np.load(\"/users/tom/git/neon_blink_detection/clip_list.npy\")\n",
    "\n",
    "of_params = OfParams(n_layers=5, layer_interval=7, average=False, img_shape=(64, 64), grid_size=20, step_size=7, window_size=11, stop_steps=3)\n",
    "\n",
    "aug_params_options = get_augmentation_options()\n",
    "aug_params = aug_params_options[0]\n",
    "\n",
    "rec = video_loader(of_params, aug_params)\n",
    "\n",
    "rec.collect(clip_names, bg_ratio=1, augment=False, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = concatenate(rec.all_features, clip_names)\n",
    "samples_gt = concatenate_all_samples(rec.all_samples, clip_names)\n",
    "labels = samples_gt.labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_l = features[:, :(features.shape[1] // 2)]\n",
    "features_r = features[:, (features.shape[1] // 2):]\n",
    "\n",
    "features_l = features_l.reshape(-1, 5, 20, 20)\n",
    "features_r = features_r.reshape(-1, 5, 20, 20)\n",
    "\n",
    "features = np.concatenate([features_l, features_r], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78718, 10, 20, 20)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78718, 10, 20, 20)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features\n",
    "y = labels\n",
    "\n",
    "# save X and y\n",
    "np.save(\"/users/tom/X.npy\", X)\n",
    "np.save(\"/users/tom/y.npy\", y)\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "\n",
    "scores_train = []\n",
    "scores_test = []\n",
    "i = 0\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    x_train, x_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    classifier = Classifier(classifier_params, export_path)\n",
    "    classifier.on_fit(x_train, y_train)\n",
    "\n",
    "    predictions = classifier.predict(x_train)\n",
    "    predictions = classify(predictions, pp_params)\n",
    "\n",
    "    scores_train.append(f1_score(y_train, predictions, average=None))\n",
    "\n",
    "    predictions = classifier.predict(x_test)\n",
    "    predictions = classify(predictions, pp_params)\n",
    "\n",
    "    scores_test.append(f1_score(y_test, predictions, average=None))\n",
    "\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/\")\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from training.cnn import OpticalFlowCNN, OpticalFlowDataset\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.load(\"/users/tom/X.npy\")\n",
    "y = np.load(\"/users/tom/y.npy\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = OpticalFlowCNN()\n",
    "model.train(X_train, y_train, num_epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax() got an unexpected keyword argument 'axis'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_dataset \u001b[39m=\u001b[39m OpticalFlowDataset(X_test)\n\u001b[0;32m----> 2\u001b[0m np\u001b[39m.\u001b[39;49margmax(model(test_dataset\u001b[39m.\u001b[39;49mX))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[39mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m-> 1216\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/numpy/core/fromnumeric.py:66\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(asarray(obj), method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/torch/_tensor.py:732\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    731\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    733\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "test_dataset = OpticalFlowDataset(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 2, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(test_dataset.X).detach().numpy()\n",
    "np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95631268, 0.82742065, 0.85142417])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9348\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "# Create a test dataset and DataLoader\n",
    "test_dataset = OpticalFlowDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Lists to store predictions and true labels\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "# Loop through the test dataset\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Pass the inputs to the model\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get the predicted class labels\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Store the predictions and true labels\n",
    "        predicted_labels.extend(predicted.numpy())\n",
    "        true_labels.extend(labels.numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.sum(np.array(predicted_labels) == np.array(true_labels)) / len(true_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pred, true \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test, y_test)\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[39m.\u001b[39mplot(pred\u001b[39m-\u001b[39;49mtrue)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "pred, true = model.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m report_dict \u001b[39m=\u001b[39m classification_report(true_labels, predicted_labels, target_names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39monset\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moffset\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbackground\u001b[39m\u001b[39m'\u001b[39m], output_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(true_labels, predicted_labels, target_names=['onset', 'offset', 'background'], output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       onset       0.95      0.97      0.96     14255\n",
      "      offset       0.88      0.81      0.85      1977\n",
      "  background       0.89      0.85      0.87      3448\n",
      "\n",
      "    accuracy                           0.93     19680\n",
      "   macro avg       0.91      0.88      0.89     19680\n",
      "weighted avg       0.93      0.93      0.93     19680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculate classification metrics\n",
    "report = classification_report(true_labels, predicted_labels, target_names=['onset', 'offset', 'background'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/\")\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from training.cnn import OpticalFlowCNN, OpticalFlowDataset\n",
    "import torch.optim as optim\n",
    "import torch \n",
    "\n",
    "def run_cnn(X, y, num_epochs=20, batch_size=32, lr=0.001, momentum=0.9):\n",
    "\n",
    "    model = OpticalFlowCNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    optical_flow_data = OpticalFlowDataset(X_train, y_train)\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(optical_flow_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\n",
    "                    \"/users/tom/git/neon_blink_detection/clip_list.npy\"\n",
    "                ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tom_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
