{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>**Compare results across classifiers and parameters**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB** with or without second classifier (always XGB) <br>\n",
    "**CNN** with or without second classifier (always XGB) <br><br>\n",
    "<i>Both across various optical flow parameters</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/\")\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/src\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cnn_path = \"/users/tom/git/neon_blink_detection/training-XGBClassifier-3-200320231657/n_lay5-lay_intv7-grid4-win15-trans0.0-scale0.0-speed0.0/results.pkl\"\n",
    "\n",
    "with open(cnn_path, 'rb') as f:\n",
    "    cnn_results = pickle.load(f)\n",
    "\n",
    "xgb_path = \"/users/tom/git/neon_blink_detection/training-XGBClassifier-3-100320231148/n_lay5-lay_intv7-grid4-win15-trans0.0-scale0.0/results.pkl\"\n",
    "\n",
    "with open(xgb_path, 'rb') as f:\n",
    "    xgb_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = cnn_results.metrics_sample_val\n",
    "\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "mean_precision_cnn = np.mean([cnn_results.metrics_pp_val.scores_list[x].F1 for x in range(5)])\n",
    "mean_recall_cnn = np.mean([cnn_results.metrics_pp_val.scores_list[x].recall for x in range(5)])\n",
    "mean_f1_score_cnn = np.mean([cnn_results.metrics_pp_val.scores_list[x].precision for x in range(5)])\n",
    "\n",
    "mean_precision_xgb = np.mean([xgb_results.metrics_pp_val.scores_list[x].F1 for x in range(5)])\n",
    "mean_recall_xgb = np.mean([xgb_results.metrics_pp_val.scores_list[x].recall for x in range(5)])\n",
    "mean_f1_score_xgb = np.mean([xgb_results.metrics_pp_val.scores_list[x].precision for x in range(5)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN\n",
      "--------------------\n",
      "Precision:  0.9487285807744603\n",
      "Recall:  0.9711876729965162\n",
      "F1 Score:  0.9275466876311128\n",
      "XGB\n",
      "--------------------\n",
      "Precision:  0.9338402586407414\n",
      "Recall:  0.960949825028932\n",
      "F1 Score:  0.9087036289905799\n"
     ]
    }
   ],
   "source": [
    "# print results in a visally appealing way\n",
    "print(\"CNN\")\n",
    "print(\"--------------------\")\n",
    "print(\"Precision: \", mean_precision_cnn)\n",
    "print(\"Recall: \", mean_recall_cnn)\n",
    "print(\"F1 Score: \", mean_f1_score_cnn)\n",
    "print(\"XGB\")\n",
    "print(\"--------------------\")\n",
    "print(\"Precision: \", mean_precision_xgb)\n",
    "print(\"Recall: \", mean_recall_xgb)\n",
    "print(\"F1 Score: \", mean_f1_score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_precision_cnn = np.mean([cnn_results.metrics_pp_test.scores_list[x].F1 for x in range(5)])\n",
    "mean_recall_cnn = np.mean([cnn_results.metrics_pp_test.scores_list[x].recall for x in range(5)])\n",
    "mean_f1_score_cnn = np.mean([cnn_results.metrics_pp_test.scores_list[x].precision for x in range(5)])\n",
    "\n",
    "mean_precision_xgb = np.mean([xgb_results.metrics_pp_test.scores_list[x].F1 for x in range(5)])\n",
    "mean_recall_xgb = np.mean([xgb_results.metrics_pp_test.scores_list[x].recall for x in range(5)])\n",
    "mean_f1_score_xgb = np.mean([xgb_results.metrics_pp_test.scores_list[x].precision for x in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN\n",
      "--------------------\n",
      "Precision:  0.961206568381202\n",
      "Recall:  0.9772771792360431\n",
      "F1 Score:  0.9457606414262774\n",
      "XGB\n",
      "--------------------\n",
      "Precision:  0.9603155706528002\n",
      "Recall:  0.9808031341821742\n",
      "F1 Score:  0.9407025566034226\n"
     ]
    }
   ],
   "source": [
    "# print results in a visally appealing way\n",
    "print(\"CNN\")\n",
    "print(\"--------------------\")\n",
    "print(\"Precision: \", mean_precision_cnn)\n",
    "print(\"Recall: \", mean_recall_cnn)\n",
    "print(\"F1 Score: \", mean_f1_score_cnn)\n",
    "print(\"XGB\")\n",
    "print(\"--------------------\")\n",
    "print(\"Precision: \", mean_precision_xgb)\n",
    "print(\"Recall: \", mean_recall_xgb)\n",
    "print(\"F1 Score: \", mean_f1_score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9407025566034226"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_f1_score_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1233074, 454176, 300879, 104046, 189164, 159913]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_results.metrics_pp_val.n_samples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F1',\n",
       " 'FN',\n",
       " 'FP',\n",
       " 'IoU',\n",
       " 'RTD_offset',\n",
       " 'RTD_onset',\n",
       " 'RTO_offset',\n",
       " 'RTO_onset',\n",
       " 'TP',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__dataclass_fields__',\n",
       " '__dataclass_params__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__match_args__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'confusion_matrix',\n",
       " 'deletions',\n",
       " 'duration_gt',\n",
       " 'duration_pd',\n",
       " 'insertions',\n",
       " 'mean_IoU',\n",
       " 'precision',\n",
       " 'recall',\n",
       " 'replace']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cnn_results.metrics_pp_val.scores_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "options 5\n",
      "\n",
      "Loading clip: 1316-2023-02-03-09-34-09-31ef7938\n",
      "Number of clips: 4\n",
      "\n",
      "Loading clip: 1311-2023-02-02-14-30-40-96be0928\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1312-2023-02-02-16-21-47-cd28e8e0\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1313-2023-02-02-16-31-53-67b1bdbe\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1329-2023-02-06-10-40-29-c4308424\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1332-2023-02-06-11-58-03-8fc75e25\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1333-2023-02-06-13-17-50-ebc1e021\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1336-2023-02-06-15-28-30-adb9dbfb\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1337-2023-02-06-15-36-31-211278ea\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1338-2023-02-06-16-29-00-adceb23d\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1339-2023-02-06-17-24-49-5b24f5ba\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1340-2023-02-06-17-37-00-e6218648\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1341-2023-02-07-10-38-42-d828e5ac\n",
      "Number of clips: 4\n",
      "\n",
      "Loading clip: 1342-2023-02-07-10-43-55-b5709e1f\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1343-2023-02-07-11-37-02-214c1078\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1345-2023-02-07-13-19-29-f5930ed0\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1344-2023-02-07-13-19-49-d1517542\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1346-2023-02-07-14-22-59-b1384544\n",
      "Number of clips: 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/\")\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/src\")\n",
    "\n",
    "from training.evaluation import evaluate\n",
    "from training.helper import ClassifierParams, Results\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from copy import copy\n",
    "from functions.classifiers import Classifier, load_predictions, save_predictions\n",
    "from src.post_processing import classify\n",
    "from src.neon_blink_detector import get_params\n",
    "of_params, pp_params, _ = get_params()\n",
    "from src.features_calculator import create_grids\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from random import choices\n",
    "from training.datasets_loader import (\n",
    "    concatenate,\n",
    "    concatenate_all_samples,\n",
    ")\n",
    "from training.helper import (\n",
    "    get_augmentation_options,\n",
    "    get_export_dir,\n",
    "    get_training_dir,\n",
    ")\n",
    "from src.event_array import Samples\n",
    "from src.helper import OfParams, PPParams, AugParams\n",
    "from training.helper import get_experiment_name_new\n",
    "from training.video_loader import video_loader\n",
    "\n",
    "clip_names = np.load(\"/users/tom/git/neon_blink_detection/clip_list.npy\")\n",
    "\n",
    "of_params = OfParams(n_layers=5, layer_interval=7, average=False, img_shape=(64, 64), grid_size=20, step_size=7, window_size=11, stop_steps=3)\n",
    "\n",
    "aug_params_options = get_augmentation_options()\n",
    "aug_params = aug_params_options[0]\n",
    "\n",
    "rec = video_loader(of_params, aug_params)\n",
    "\n",
    "rec.collect(clip_names, bg_ratio=1, augment=False, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from src.post_processing import post_process\n",
    "from functions.classifiers import Classifier\n",
    "from functions.pipeline import get_classifier_params\n",
    "\n",
    "features = concatenate(rec.all_features, clip_names)\n",
    "samples_gt = concatenate_all_samples(rec.all_samples, clip_names)\n",
    "labels = samples_gt.labels\n",
    "\n",
    "xgb_path = \"/users/tom/git/neon_blink_detection/training-XGBClassifier-3-100320231148/n_lay5-lay_intv7-grid4-win15-trans0.0-scale0.0/results.pkl\"\n",
    "\n",
    "clf_path = \"/users/tom/git/neon_blink_detection/weights/xgb.sav\"\n",
    "clf = joblib.load(str(clf_path))\n",
    "\n",
    "classifier_params = get_classifier_params(type=\"XGB\", use_second_classifier=False)\n",
    "clf_path = \"/users/tom/git/neon_blink_detection/weights/\"\n",
    "clf = Classifier(classifier_params, clf_path)\n",
    "clf.load_base_classifier(idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 160, got 4000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clf\u001b[39m.\u001b[39;49mpredict_all_clips(rec\u001b[39m.\u001b[39;49mall_features)\n",
      "File \u001b[0;32m/users/tom/git/neon_blink_detection/functions/utils.py:17\u001b[0m, in \u001b[0;36mtimer.<locals>.wrapper_timer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper_timer\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     16\u001b[0m     t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m---> 17\u001b[0m     output \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     18\u001b[0m     t2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m     20\u001b[0m     run_time \u001b[39m=\u001b[39m t2 \u001b[39m-\u001b[39m t1\n",
      "File \u001b[0;32m/users/tom/git/neon_blink_detection/functions/classifiers.py:41\u001b[0m, in \u001b[0;36mClassifier.predict_all_clips\u001b[0;34m(self, all_features)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m@timer\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_all_clips\u001b[39m(\n\u001b[1;32m     38\u001b[0m     \u001b[39mself\u001b[39m, all_features: T\u001b[39m.\u001b[39mDict[\u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray]\n\u001b[1;32m     39\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T\u001b[39m.\u001b[39mDict[\u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray]:\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     42\u001b[0m         clip_tuple: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(features)\n\u001b[1;32m     43\u001b[0m         \u001b[39mfor\u001b[39;00m clip_tuple, features \u001b[39min\u001b[39;00m all_features\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     44\u001b[0m     }\n",
      "File \u001b[0;32m/users/tom/git/neon_blink_detection/functions/classifiers.py:42\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m@timer\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_all_clips\u001b[39m(\n\u001b[1;32m     38\u001b[0m     \u001b[39mself\u001b[39m, all_features: T\u001b[39m.\u001b[39mDict[\u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray]\n\u001b[1;32m     39\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T\u001b[39m.\u001b[39mDict[\u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray]:\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m---> 42\u001b[0m         clip_tuple: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(features)\n\u001b[1;32m     43\u001b[0m         \u001b[39mfor\u001b[39;00m clip_tuple, features \u001b[39min\u001b[39;00m all_features\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     44\u001b[0m     }\n",
      "File \u001b[0;32m/users/tom/git/neon_blink_detection/functions/classifiers.py:34\u001b[0m, in \u001b[0;36mClassifier.predict\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, features: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclf\u001b[39m.\u001b[39;49mpredict_proba(features)\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/xgboost/sklearn.py:1348\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[0;34m(self, X, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Predict the probability of each `X` example being of a given class.\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m \n\u001b[1;32m   1318\u001b[0m \u001b[39m.. note:: This function is only thread safe for `gbtree` and `dart`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[39m    probability of each data example being of a given class.\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[39m# custom obj:      Do nothing as we don't know what to do.\u001b[39;00m\n\u001b[1;32m   1344\u001b[0m \u001b[39m# softprob:        Do nothing, output is proba.\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m \u001b[39m# softmax:         Use output margin to remove the argmax in PredTransform.\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[39m# binary:logistic: Expand the prob vector into 2-class matrix after predict.\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m \u001b[39m# binary:logitraw: Unsupported by predict_proba()\u001b[39;00m\n\u001b[0;32m-> 1348\u001b[0m class_probs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m   1349\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1350\u001b[0m     output_margin\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjective \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmulti:softmax\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1351\u001b[0m     ntree_limit\u001b[39m=\u001b[39;49mntree_limit,\n\u001b[1;32m   1352\u001b[0m     validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1353\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1354\u001b[0m     iteration_range\u001b[39m=\u001b[39;49miteration_range\n\u001b[1;32m   1355\u001b[0m )\n\u001b[1;32m   1356\u001b[0m \u001b[39m# If model is loaded from a raw booster there's no `n_classes_`\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m \u001b[39mreturn\u001b[39;00m _cls_predict_proba(\n\u001b[1;32m   1358\u001b[0m     \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_classes_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m), class_probs, np\u001b[39m.\u001b[39mvstack\n\u001b[1;32m   1359\u001b[0m )\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/xgboost/sklearn.py:881\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m    880\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 881\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[1;32m    882\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    883\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[1;32m    884\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    885\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m    886\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    887\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m    888\u001b[0m         )\n\u001b[1;32m    889\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m    890\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m     \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/xgboost/core.py:2018\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2015\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2016\u001b[0m         )\n\u001b[1;32m   2017\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features() \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m-> 2018\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2019\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature shape mismatch, expected: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features()\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2020\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2021\u001b[0m         )\n\u001b[1;32m   2023\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m _is_pandas_df, _transform_pandas_df\n\u001b[1;32m   2024\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m _array_interface\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 160, got 4000"
     ]
    }
   ],
   "source": [
    "clf.predict_all_clips(rec.all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3752, 4000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tom_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
