{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "options 1\n",
      "\n",
      "Loading clip: 1000-2022-12-14-09-43-56-0fcac6d3\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1002-2022-12-14-11-43-58-23e05b8c\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1004-2022-12-14-13-14-14-c8a509b9\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1005-2022-12-14-15-07-31-ba8d94d5\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 1010-2022-12-15-13-27-31-f46dcdd8\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 1140-2023-01-12-13-15-56-2f0172d2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m aug_params \u001b[39m=\u001b[39m aug_params_options[\u001b[39m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m rec \u001b[39m=\u001b[39m video_loader(of_params, aug_params)\n\u001b[0;32m---> 24\u001b[0m rec\u001b[39m.\u001b[39;49mcollect(clip_names, bg_ratio\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, augment\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, idx\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/users/tom/git/neon_blink_detection/training/video_loader.py:65\u001b[0m, in \u001b[0;36mvideo_loader.collect\u001b[0;34m(self, clip_names, bg_ratio, augment, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_augmented(clip_name, bg_ratio, augment, idx)\n\u001b[1;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_legacy(clip_name, bg_ratio)\n",
      "File \u001b[0;32m/users/tom/git/neon_blink_detection/training/video_loader.py:193\u001b[0m, in \u001b[0;36mvideo_loader._load_legacy\u001b[0;34m(self, clip_name, bg_ratio)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_legacy\u001b[39m(\u001b[39mself\u001b[39m, clip_name: \u001b[39mstr\u001b[39m, bg_ratio: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m \n\u001b[1;32m    192\u001b[0m     \u001b[39m# LOAD FEATURES OR COMPUTE THEM\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     feature_array, all_timestamps, clip_transitions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_features(\n\u001b[1;32m    194\u001b[0m         clip_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_of_params\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    197\u001b[0m     n_clips \u001b[39m=\u001b[39m clip_transitions\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    198\u001b[0m     clip_feature_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msplit(feature_array, clip_transitions \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/users/tom/git/neon_blink_detection/training/video_loader.py:259\u001b[0m, in \u001b[0;36mvideo_loader._load_features\u001b[0;34m(self, clip_name, of_params)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     tmp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(path)\n\u001b[0;32m--> 259\u001b[0m     feature_array \u001b[39m=\u001b[39m tmp[\u001b[39m\"\u001b[39;49m\u001b[39mfeature_array\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    260\u001b[0m     clip_transitions \u001b[39m=\u001b[39m tmp[\u001b[39m\"\u001b[39m\u001b[39mclip_transitions\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    261\u001b[0m     timestamps \u001b[39m=\u001b[39m tmp[\u001b[39m\"\u001b[39m\u001b[39mtimestamps\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/numpy/lib/npyio.py:253\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m magic \u001b[39m==\u001b[39m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    252\u001b[0m     \u001b[39mbytes\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mopen(key)\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(\u001b[39mbytes\u001b[39;49m,\n\u001b[1;32m    254\u001b[0m                              allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallow_pickle,\n\u001b[1;32m    255\u001b[0m                              pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpickle_kwargs,\n\u001b[1;32m    256\u001b[0m                              max_header_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_header_size)\n\u001b[1;32m    257\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mread(key)\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/numpy/lib/format.py:812\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    810\u001b[0m             read_count \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(max_read_count, count \u001b[39m-\u001b[39m i)\n\u001b[1;32m    811\u001b[0m             read_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(read_count \u001b[39m*\u001b[39m dtype\u001b[39m.\u001b[39mitemsize)\n\u001b[0;32m--> 812\u001b[0m             data \u001b[39m=\u001b[39m _read_bytes(fp, read_size, \u001b[39m\"\u001b[39;49m\u001b[39marray data\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    813\u001b[0m             array[i:i\u001b[39m+\u001b[39mread_count] \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mfrombuffer(data, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m    814\u001b[0m                                                      count\u001b[39m=\u001b[39mread_count)\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m fortran_order:\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/site-packages/numpy/lib/format.py:947\u001b[0m, in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    943\u001b[0m     \u001b[39m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[1;32m    944\u001b[0m     \u001b[39m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[1;32m    945\u001b[0m     \u001b[39m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[1;32m    946\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 947\u001b[0m         r \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(size \u001b[39m-\u001b[39;49m \u001b[39mlen\u001b[39;49m(data))\n\u001b[1;32m    948\u001b[0m         data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m r\n\u001b[1;32m    949\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(r) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m==\u001b[39m size:\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/zipfile.py:925\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    924\u001b[0m \u001b[39mwhile\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n\u001b[0;32m--> 925\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read1(n)\n\u001b[1;32m    926\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[1;32m    927\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readbuffer \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m/cluster/anaconda3/envs/tom_py310/lib/python3.10/zipfile.py:1001\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_type \u001b[39m==\u001b[39m ZIP_DEFLATED:\n\u001b[1;32m   1000\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(n, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMIN_READ_SIZE)\n\u001b[0;32m-> 1001\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(data, n)\n\u001b[1;32m   1002\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39meof \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m                  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_left \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m                  \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail)\n\u001b[1;32m   1005\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/\")\n",
    "sys.path.append(\"/users/tom/git/neon_blink_detection/src\")\n",
    "\n",
    "from training.helper import ClassifierParams, Results\n",
    "from src.neon_blink_detector import get_params\n",
    "of_params, pp_params, _ = get_params()\n",
    "import numpy as np\n",
    "from training.helper import get_augmentation_options\n",
    "from src.helper import OfParams, PPParams, AugParams\n",
    "from training.video_loader import video_loader\n",
    "from training.datasets_loader import concatenate_all_samples, concatenate\n",
    "\n",
    "clip_names = np.load(\"/users/tom/git/neon_blink_detection/clip_list.npy\")\n",
    "\n",
    "of_params = OfParams(n_layers=5, layer_interval=7, average=False, img_shape=(64, 64), grid_size=4, step_size=7, window_size=11, stop_steps=3)\n",
    "\n",
    "aug_params_options = get_augmentation_options()\n",
    "aug_params = aug_params_options[0]\n",
    "\n",
    "rec = video_loader(of_params, aug_params)\n",
    "\n",
    "rec.collect(clip_names, bg_ratio=1, augment=False, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/tom/git/neon_blink_detection/training/cnn.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n",
      "/users/tom/git/neon_blink_detection/training/cnn.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Validation loss: 0.26984216694305413\n",
      "Epoch 2/100\n",
      "Validation loss: 0.23062998276666133\n",
      "Epoch 3/100\n",
      "Validation loss: 0.20695850293893014\n",
      "Epoch 4/100\n",
      "Validation loss: 0.1894970672055535\n",
      "Epoch 5/100\n",
      "Validation loss: 0.1795741290017201\n",
      "Epoch 6/100\n",
      "Validation loss: 0.17512992568259692\n",
      "Epoch 7/100\n",
      "Validation loss: 0.17496164998270736\n",
      "Epoch 8/100\n",
      "Validation loss: 0.16099902608832956\n",
      "Epoch 9/100\n",
      "Validation loss: 0.15243457471204064\n",
      "Epoch 10/100\n",
      "Validation loss: 0.15183160753145705\n",
      "Epoch 11/100\n",
      "Validation loss: 0.15173971292691946\n",
      "Epoch 12/100\n",
      "Validation loss: 0.1433104367885929\n",
      "Epoch 13/100\n",
      "Validation loss: 0.143464439011512\n",
      "Epoch 14/100\n",
      "Validation loss: 0.1430923905781042\n",
      "Epoch 15/100\n",
      "Validation loss: 0.141280961936734\n",
      "Epoch 16/100\n",
      "Validation loss: 0.13528128966254038\n",
      "Epoch 17/100\n",
      "Validation loss: 0.1268652409355897\n",
      "Epoch 18/100\n",
      "Validation loss: 0.1266434966674904\n",
      "Epoch 19/100\n",
      "Validation loss: 0.12917113724932835\n",
      "Epoch 20/100\n",
      "Validation loss: 0.12388510059864416\n",
      "Epoch 21/100\n",
      "Validation loss: 0.1348867277703146\n",
      "Epoch 22/100\n",
      "Validation loss: 0.12332034810534577\n",
      "Epoch 23/100\n",
      "Validation loss: 0.12092184616647063\n",
      "Epoch 24/100\n",
      "Validation loss: 0.11660521376171033\n",
      "Epoch 25/100\n",
      "Validation loss: 0.12079299956451367\n",
      "Epoch 26/100\n",
      "Validation loss: 0.12599711562336904\n",
      "Epoch 27/100\n",
      "Validation loss: 0.11637261398408534\n",
      "Epoch 28/100\n",
      "Validation loss: 0.11851913332735209\n",
      "Early stopping after 28 epochs\n"
     ]
    }
   ],
   "source": [
    "from training.cnn import OpticalFlowCNN, OpticalFlowDataset\n",
    "from training.run_one import train_cnn\n",
    "\n",
    "classifier, scores = train_cnn(\n",
    "            rec,\n",
    "            clip_names,\n",
    "            classifier_params=None,\n",
    "            export_path=None,\n",
    "            idx=0,\n",
    "            augment_data=False,\n",
    "            pp_params=pp_params,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = concatenate(rec.all_features, clip_names)\n",
    "samples_gt = concatenate_all_samples(rec.all_samples, clip_names)\n",
    "labels = samples_gt.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/tom/git/neon_blink_detection/training/cnn.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch_features = torch.from_numpy(features).float().cuda()\n",
    "cnn_features = classifier.predict(torch_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 50\n",
    "\n",
    "indices = np.arange(0, features.shape[0])\n",
    "all_indices = np.array([np.arange(index - length, index + length) for index in indices])\n",
    "all_indices = np.clip(all_indices, 0, features.shape[0]-1)\n",
    "\n",
    "all_cnn_features = np.array(cnn_features[all_indices, :].reshape(-1, 2*length * 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_fit took 1 m 41 s\n"
     ]
    }
   ],
   "source": [
    "# import xgb classifi\n",
    "from functions.classifiers import Classifier as XGB\n",
    "from functions.pipeline import get_classifier_params\n",
    "\n",
    "classifier_params = get_classifier_params()\n",
    "xgb = XGB(classifier_params)\n",
    "xgb.on_fit(features=all_cnn_features, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading clip: 2023-03-01_09-59-07-2ea49126\n",
      "Number of clips: 2\n",
      "\n",
      "Loading clip: 2023-01-27_15-59-54-49a115d5\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 2023-02-01_11-45-11-7621531e\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 2023-01-27_16-10-14-a2a8cbe1\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 2023-01-27_16-15-26-57802f75\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 2023-01-27_16-24-04-eb4305b1\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: 2023-01-27_16-31-52-5f743ed0\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: padel_tennis_neon_01-b922b245\n",
      "Number of clips: 1\n",
      "\n",
      "Loading clip: padel_tennis_neon_03-2ded8f56\n",
      "Number of clips: 1\n"
     ]
    }
   ],
   "source": [
    "clip_names_test = [\n",
    "    \"2023-03-01_09-59-07-2ea49126\",  # kai bike\n",
    "    \"2023-01-27_15-59-54-49a115d5\",  # tom computer\n",
    "    \"2023-02-01_11-45-11-7621531e\",  # kai computer\n",
    "    \"2023-01-27_16-10-14-a2a8cbe1\",  # ryan discussing\n",
    "    \"2023-01-27_16-15-26-57802f75\",  # tom walking\n",
    "    \"2023-01-27_16-24-04-eb4305b1\",  # kai walking\n",
    "    \"2023-01-27_16-31-52-5f743ed0\",  # moritz snowboarding\n",
    "    \"padel_tennis_neon_01-b922b245\",  # mgg padel\n",
    "    \"padel_tennis_neon_03-2ded8f56\",  # mgg partner padel\n",
    "]\n",
    "\n",
    "rec.collect(clip_names_test, bg_ratio=1, augment=False, idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = concatenate(rec.all_features, clip_names_test)\n",
    "samples_gt = concatenate_all_samples(rec.all_samples, clip_names_test)\n",
    "labels = samples_gt.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(0, features.shape[0])\n",
    "all_indices = np.array([np.arange(index - length, index + length) for index in indices])\n",
    "all_indices = np.clip(all_indices, 0, features.shape[0]-1)\n",
    "\n",
    "torch_features_test = torch.from_numpy(features).float().cuda()\n",
    "cnn_features_test = classifier.predict(torch_features_test)\n",
    "all_cnn_features_test = np.array(cnn_features_test[all_indices, :].reshape(-1, 2 * length * 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.argmax(xgb.predict(all_cnn_features_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m f1_score, recall_score, precision_score\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(f1_score(labels, pred_labels, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(recall_score(labels, pred_labels,  average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(precision_score(labels, pred_labels,  average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "print(f1_score(labels, pred_labels, average=\"macro\"))\n",
    "print(recall_score(labels, pred_labels,  average=\"macro\"))\n",
    "print(precision_score(labels, pred_labels,  average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176021, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.94316394 0.82210183 0.80179752]\n",
    "[0.97496918 0.77304153 0.72975878]\n",
    "[0.91336824 0.87781123 0.88961677]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tom_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
